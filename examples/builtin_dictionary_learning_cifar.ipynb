{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from lcapt.lca import LCAConv2D\n",
    "from lcapt.metric import compute_l1_sparsity, compute_l2_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "FEATURES = 64  # number of dictionary features to learn\n",
    "KERNEL_SIZE = 9  # height and width of each feature\n",
    "LAMBDA = 0.25  # LCA threshold\n",
    "PRINT_FREQ = 10\n",
    "STRIDE = 2  # convolutional stride\n",
    "TAU = 200  # LCA time constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = CIFAR10('./data', download=True, transform=ToTensor())\n",
    "dataloader = DataLoader(dset, BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lca = LCAConv2D(\n",
    "    n_neurons=FEATURES,\n",
    "    in_c=3,\n",
    "    result_dir='./cifar_dictionary_learning',\n",
    "    kh=KERNEL_SIZE,\n",
    "    kw=KERNEL_SIZE,\n",
    "    stride_h=STRIDE,\n",
    "    stride_w=STRIDE,\n",
    "    lambda_=LAMBDA,\n",
    "    tau=TAU,\n",
    "    return_all=True,\n",
    "    track_metrics=True\n",
    ")\n",
    "if torch.cuda.is_available():\n",
    "    lca = torch.nn.DataParallel(lca).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for batch_num, (images, _) in enumerate(dataloader):\n",
    "        code, recon, recon_error, _, _ = lca(images)\n",
    "        lca.module.update_weights(code, recon_error)\n",
    "        if batch_num % PRINT_FREQ == 0:\n",
    "            l1_sparsity = compute_l1_sparsity(code, lca.module.lambda_).item()\n",
    "            l2_recon_error = compute_l2_error(recon_error + recon, recon).item()\n",
    "            total_energy = l2_recon_error + l1_sparsity\n",
    "            print(f'L2 Recon Error: {round(l2_recon_error, 2)}; ',\n",
    "                  f'L1 Sparsity: {round(l1_sparsity, 2)}; ',\n",
    "                  f'Total Energy: {round(total_energy, 2)}')\n",
    "    torch.save(lca, f'save_{epoch}.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd45d772aae72a996d88094ff1d23a9b9559c03a306cb19d60e1001da0c23d24"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('lcapt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
